{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "cN9jAr3jsEg2",
        "UwU3r8s1t9Ny",
        "A95ZDKU9u0Yb",
        "PRi2cNP3x-d7",
        "aF_kyBZ8rwbO",
        "Uft5hfKGr4ln",
        "e97MYcS6snLD"
      ],
      "mount_file_id": "1HMzWZ7f8vYgysfOFe3F_6-KuXD4VjxCN",
      "authorship_tag": "ABX9TyPoBliXKa31nY7LEtuEZS3I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhishekmishra-bareilly/Deep-Learning/blob/main/All_Text_Preprocessing_for_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the dependancy\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "kfn3yqZDrLKg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/PYTHON/colab with data/imdb/imdb_data.csv')"
      ],
      "metadata": {
        "id": "4udQx1bNq5QQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "TrJA00BFrSa_",
        "outputId": "a37eb6a1-da13-4eec-e536-3c0284f15577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                              belongs_to_collection    budget  \\\n",
              "0   1  [{'id': 313576, 'name': 'Hot Tub Time Machine ...  14000000   \n",
              "\n",
              "                           genres homepage    imdb_id original_language  \\\n",
              "0  [{'id': 35, 'name': 'Comedy'}]      NaN  tt2637294                en   \n",
              "\n",
              "           original_title                                           overview  \\\n",
              "0  Hot Tub Time Machine 2  When Lou, who has become the \"father of the In...   \n",
              "\n",
              "   popularity  ... release_date runtime  \\\n",
              "0    6.575393  ...      2/20/15    93.0   \n",
              "\n",
              "                           spoken_languages    status  \\\n",
              "0  [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
              "\n",
              "                                             tagline                   title  \\\n",
              "0  The Laws of Space and Time are About to be Vio...  Hot Tub Time Machine 2   \n",
              "\n",
              "                                            Keywords  \\\n",
              "0  [{'id': 4379, 'name': 'time travel'}, {'id': 9...   \n",
              "\n",
              "                                                cast  \\\n",
              "0  [{'cast_id': 4, 'character': 'Lou', 'credit_id...   \n",
              "\n",
              "                                                crew   revenue  \n",
              "0  [{'credit_id': '59ac067c92514107af02c8c8', 'de...  12314651  \n",
              "\n",
              "[1 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1fdcca8-1dc2-4fc7-b147-eda6451fd5f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>belongs_to_collection</th>\n",
              "      <th>budget</th>\n",
              "      <th>genres</th>\n",
              "      <th>homepage</th>\n",
              "      <th>imdb_id</th>\n",
              "      <th>original_language</th>\n",
              "      <th>original_title</th>\n",
              "      <th>overview</th>\n",
              "      <th>popularity</th>\n",
              "      <th>...</th>\n",
              "      <th>release_date</th>\n",
              "      <th>runtime</th>\n",
              "      <th>spoken_languages</th>\n",
              "      <th>status</th>\n",
              "      <th>tagline</th>\n",
              "      <th>title</th>\n",
              "      <th>Keywords</th>\n",
              "      <th>cast</th>\n",
              "      <th>crew</th>\n",
              "      <th>revenue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[{'id': 313576, 'name': 'Hot Tub Time Machine ...</td>\n",
              "      <td>14000000</td>\n",
              "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>tt2637294</td>\n",
              "      <td>en</td>\n",
              "      <td>Hot Tub Time Machine 2</td>\n",
              "      <td>When Lou, who has become the \"father of the In...</td>\n",
              "      <td>6.575393</td>\n",
              "      <td>...</td>\n",
              "      <td>2/20/15</td>\n",
              "      <td>93.0</td>\n",
              "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
              "      <td>Released</td>\n",
              "      <td>The Laws of Space and Time are About to be Vio...</td>\n",
              "      <td>Hot Tub Time Machine 2</td>\n",
              "      <td>[{'id': 4379, 'name': 'time travel'}, {'id': 9...</td>\n",
              "      <td>[{'cast_id': 4, 'character': 'Lou', 'credit_id...</td>\n",
              "      <td>[{'credit_id': '59ac067c92514107af02c8c8', 'de...</td>\n",
              "      <td>12314651</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows Ã— 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1fdcca8-1dc2-4fc7-b147-eda6451fd5f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e1fdcca8-1dc2-4fc7-b147-eda6451fd5f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e1fdcca8-1dc2-4fc7-b147-eda6451fd5f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Convert text into lower case**"
      ],
      "metadata": {
        "id": "cN9jAr3jsEg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['original_title'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "M4UwL2jDrULV",
        "outputId": "7b7bf90e-1ad2-468a-f9e6-b861f9d473cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hot Tub Time Machine 2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['original_title'][0].lower()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "vEADaU39sBbf",
        "outputId": "51f50cef-87ff-4f67-c929-5bad6a9f6d08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hot tub time machine 2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply on the column\n",
        "data['original_title'] = data['original_title'].str.lower()"
      ],
      "metadata": {
        "id": "5sYC_NAQsZTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['original_title'].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEdQugS8srFh",
        "outputId": "37319efd-f34d-4999-ba0c-1d110af7e085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['hot tub time machine 2',\n",
              "       'the princess diaries 2: royal engagement', 'whiplash', ...,\n",
              "       'the long kiss goodnight', 'along came polly', 'abduction'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Remove html tags**"
      ],
      "metadata": {
        "id": "UwU3r8s1t9Ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"<html><body><p> Movie 1</p><p> Actor - Aamir Khan</p><p> Click here to <a href='http://google.com'>download</a></p></body></html>\""
      ],
      "metadata": {
        "id": "7Fu4_aawsv-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function to remove all html tags\n",
        "import re\n",
        "def remove_html_tags(text):\n",
        "    pattern = re.compile('<.*?>')\n",
        "    return pattern.sub(r'', text)"
      ],
      "metadata": {
        "id": "7ifAy15auIPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_html_tags(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3FwnIbDeugtH",
        "outputId": "3bd94482-cc40-478f-8ba9-f8a8fcf4ecbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Movie 1 Actor - Aamir Khan Click here to download'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Remove all url**"
      ],
      "metadata": {
        "id": "A95ZDKU9u0Yb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = 'Check out my notebook https://www.kaggle.com/campusx/notebook8223fc1abb'\n",
        "text2 = 'Check out my notebook http://www.kaggle.com/campusx/notebook8223fc1abb'\n",
        "text3 = 'Google search here www.google.com'\n",
        "text4 = 'For notebook click https://www.kaggle.com/campusx/notebook8223fc1abb to search check www.google.com'"
      ],
      "metadata": {
        "id": "fg0dVY1NumeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function to Remove all url\n",
        "def remove_url(text):\n",
        "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return pattern.sub(r'', text)"
      ],
      "metadata": {
        "id": "LNPqRtaOvAj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_url(text3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "21CY55I3vK1Y",
        "outputId": "36fd4a00-65ad-431c-fbf3-bb00a2873ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Google search here '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Remove pancuation**"
      ],
      "metadata": {
        "id": "PRi2cNP3x-d7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string,time\n",
        "string.punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IebN5Z5cwfHk",
        "outputId": "8d4b65fe-d2ab-4cf6-86df-cee965a642f2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "punch_word = string.punctuation\n",
        "def remove_punch(text):\n",
        "  for char in punch_word:\n",
        "    text =text.replace(char, '')\n",
        "  return text"
      ],
      "metadata": {
        "id": "EXFnI59O1_Ln"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'string. With. Punctuation?'"
      ],
      "metadata": {
        "id": "lF8cHp822dkk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_punch(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nv0-qVEP2gRw",
        "outputId": "39b3cdd0-7298-4f0e-fc7a-2b30807b6812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'string With Punctuation'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Other Mathod**"
      ],
      "metadata": {
        "id": "agPH-2HKnRU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punc1(text):\n",
        "    return text.translate(str.maketrans('', '', punch_word))"
      ],
      "metadata": {
        "id": "fA0_Uta12iCT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_punc1(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0UUW7Pu7nYlf",
        "outputId": "eb7cfe1b-e148-4428-ecef-c12f25c6d46f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'string With Punctuation'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Chat word correcter**"
      ],
      "metadata": {
        "id": "aF_kyBZ8rwbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_words = {'IMHO':'In My Honest/Humble Opinion', 'gn':'Good night'}"
      ],
      "metadata": {
        "id": "QzbGvfekncwv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'IMHO he is the best'"
      ],
      "metadata": {
        "id": "03Ut4IJ_rVl2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_conversion(text):\n",
        "    new_text = []\n",
        "    for w in text.split():\n",
        "        if w.upper() in chat_words:\n",
        "            new_text.append(chat_words[w.upper()])\n",
        "        else:\n",
        "            new_text.append(w)\n",
        "    return \" \".join(new_text)"
      ],
      "metadata": {
        "id": "rJhe_QfvrLvw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_conversion('IMHO he is the best')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fj70tRe-rr9z",
        "outputId": "7ec1ad8c-a5c2-4d95-f806-ddf465442d94"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In My Honest/Humble Opinion he is the best'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Spelling Correction**"
      ],
      "metadata": {
        "id": "Uft5hfKGr4ln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the dependancy\n",
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "ipf-zdBYrtyZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "incorrect_text = 'ceertain conditionas duriing seveal ggenerations aree moodified in the saame maner.'"
      ],
      "metadata": {
        "id": "04EzLzx3sVy7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textBlb = TextBlob(incorrect_text)\n"
      ],
      "metadata": {
        "id": "57ZdhE9dsc-i"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textBlb.correct().string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "TBgzazYise32",
        "outputId": "8409fe19-ad62-4da1-a84b-23a9cdd3c607"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'certain conditions during several generations are modified in the same manner.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Stopword Removel**\n"
      ],
      "metadata": {
        "id": "e97MYcS6snLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ks1CsTaostho",
        "outputId": "ececfb90-738d-4bb7-b1bd-43db1c0f2df6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ng1Uagros9k2",
        "outputId": "4bc25c2e-9778-44be-ed39-9dfc05850612"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(text):\n",
        "    new_text = []\n",
        "    \n",
        "    for word in text.split():\n",
        "        if word in stopwords.words('english'):\n",
        "            new_text.append('')\n",
        "        else:\n",
        "            new_text.append(word)\n",
        "    x = new_text[:]\n",
        "    new_text.clear()\n",
        "    return \" \".join(x)"
      ],
      "metadata": {
        "id": "LgFgw1PptBY9"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_stopwords('probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it\\'s not preachy or boring. it just never gets old, despite my having seen it some 15 or more times')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "bBxheXolufym",
        "outputId": "61d6bac8-a795-4d28-a209-f025a7cbb35d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'probably  all-time favorite movie,  story  selflessness, sacrifice  dedication   noble cause,    preachy  boring.   never gets old, despite   seen   15   times'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Remove e-moji**"
      ],
      "metadata": {
        "id": "o8ZvML6Lujg6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove emoji**"
      ],
      "metadata": {
        "id": "J1XFZm7u2t60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)"
      ],
      "metadata": {
        "id": "XcXtUaeXwC3z"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_emoji(\"Loved the movie. It was ðŸ˜˜ðŸ˜˜\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "grA4oPMR2lmm",
        "outputId": "7dc74175-f980-4dcc-8120-61cba82c0180"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Loved the movie. It was '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Replace emoji with it's mean**"
      ],
      "metadata": {
        "id": "MQeXbZnE242y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji\n",
        "import emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFDYylpk3Ab1",
        "outputId": "e69e17a8-97c3-4547-88ea-0f36a8415e53"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 240 kB 4.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234926 sha256=87711b8d64c2c67a67564498a46acdc3319502de6ba7013c8bf4230b13e4a8e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/62/9e/a6b27a681abcde69970dbc0326ff51955f3beac72f15696984\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(emoji.demojize('Python is ðŸ”¥'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1bTNlfP3Dtd",
        "outputId": "ead0f8bc-56ea-458c-c069-537421816435"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python is :fire:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tokenization**"
      ],
      "metadata": {
        "id": "PPeygzAo3Shu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using the split function**"
      ],
      "metadata": {
        "id": "5fM2jGIY6zBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # word tokenization\n",
        "sent1 = 'I am going to delhi'\n",
        "sent1.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oxDTPNB3XDH",
        "outputId": "dcf531a8-c95e-48ba-b8e2-567d8d31307b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'am', 'going', 'to', 'delhi']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sentence tokenization\n",
        "sent2 = 'I am going to delhi. I will stay there for 3 days. Let\\'s hope the trip to be great'\n",
        "sent2.split('.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL7P-YYr67vZ",
        "outputId": "9b9d32cf-f33a-4886-cdc3-565bb987f73b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I am going to delhi',\n",
              " ' I will stay there for 3 days',\n",
              " \" Let's hope the trip to be great\"]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Problems with split function\n",
        "sent3 = 'I am going to delhi!'\n",
        "sent3.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hrz2yHCE7Dru",
        "outputId": "9ee718a2-678b-4c59-fb1f-8084ddd29e53"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'am', 'going', 'to', 'delhi!']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent4 = 'Where do think I should go? I have 3 day holiday'\n",
        "sent4.split('.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZidGn297Kcf",
        "outputId": "cce30002-ae91-443a-983a-3ec975dbcabd"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Where do think I should go? I have 3 day holiday']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Regular Expression**"
      ],
      "metadata": {
        "id": "FPAwHn5v7jb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "sent3 = 'I am going to delhi!'\n",
        "tokens = re.findall(\"[\\w']+\", sent3)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzQ094PM7kdm",
        "outputId": "45a715e2-04d7-47fd-8958-b87440c544e3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'am', 'going', 'to', 'delhi']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry? \n",
        "Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, \n",
        "when an unknown printer took a galley of type and scrambled it to make a type specimen book.\"\"\"\n",
        "sentences = re.compile('[.!?] ').split(text)\n",
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEfCWXOa7tii",
        "outputId": "06909f0c-4f5c-4ee6-8cd4-881c33d435d1"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Lorem Ipsum is simply dummy text of the printing and typesetting industry',\n",
              " \"\\nLorem Ipsum has been the industry's standard dummy text ever since the 1500s, \\nwhen an unknown printer took a galley of type and scrambled it to make a type specimen book.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLTK for Tokenization"
      ],
      "metadata": {
        "id": "nhH6pAgd7xwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uy171_ui779a",
        "outputId": "81859d95-cb67-4bcd-9041-84fc37aa1d70"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent1 = 'I am going to visit delhi!'\n",
        "word_tokenize(sent1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MD3KTVQX79we",
        "outputId": "99182474-1f78-4773-afd3-325f3be1df0b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'am', 'going', 'to', 'visit', 'delhi', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry? \n",
        "Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, \n",
        "when an unknown printer took a galley of type and scrambled it to make a type specimen book.\"\"\"\n",
        "\n",
        "sent_tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEe62JRQ8ZJa",
        "outputId": "efa5ac42-0f89-4847-901e-a62b8316acbd"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Lorem Ipsum is simply dummy text of the printing and typesetting industry?',\n",
              " \"Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, \\nwhen an unknown printer took a galley of type and scrambled it to make a type specimen book.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent5 = 'I have a Ph.D in A.I'\n",
        "sent6 = \"We're here to help! mail us at nks@gmail.com\"\n",
        "sent7 = 'A 5km ride cost $10.50'\n",
        "\n",
        "word_tokenize(sent5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4v4gA068kti",
        "outputId": "7bd58013-eb20-4d4f-9e66-2359788bd063"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'have', 'a', 'Ph.D', 'in', 'A.I']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spacy for Tokenization**"
      ],
      "metadata": {
        "id": "OTnu-2bn8oFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dee2-Tpb8sYx",
        "outputId": "6d57243b-7897-4f36-ca21-3041ec8bafad"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = nlp(sent5)\n",
        "doc2 = nlp(sent6)\n",
        "doc3 = nlp(sent7)\n",
        "doc4 = nlp(sent1)"
      ],
      "metadata": {
        "id": "bkCMnC_p9aIR"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc4:\n",
        "    print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9RpgTTm9eif",
        "outputId": "44def69d-233e-490a-ec3e-ac3b26d05287"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I\n",
            "am\n",
            "going\n",
            "to\n",
            "visit\n",
            "delhi\n",
            "!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Stemming**"
      ],
      "metadata": {
        "id": "dUbxl0qa96St"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import PorterStemmer"
      ],
      "metadata": {
        "id": "YKoZ_CMS99Ra"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ps = PorterStemmer()\n",
        "def stem_words(text):\n",
        "    return \" \".join([ps.stem(word) for word in text.split()])"
      ],
      "metadata": {
        "id": "CuDlPluu-dj1"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = \"walk walks walking walked\"\n",
        "stem_words(sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QK-4bebm-gIu",
        "outputId": "452eb773-1a18-40a0-b053-aa81ba13847b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'walk walk walk walk'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'probably my alltime favorite movie a story of selflessness sacrifice and dedication to a noble cause but its not preachy or boring it just never gets old despite my having seen it some 15 or more times in the last 25 years paul lukas performance brings tears to my eyes and bette davis in one of her very few truly sympathetic roles is a delight the kids are as grandma says more like dressedup midgets than children but that only makes them more fun to watch and the mothers slow awakening to whats happening in the world and under her own roof is believable and startling if i had a dozen thumbs theyd all be up for this movie'\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JrMSFxR-jlS",
        "outputId": "02d35f26-8efa-45e3-dded-b8b10f25ba21"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probably my alltime favorite movie a story of selflessness sacrifice and dedication to a noble cause but its not preachy or boring it just never gets old despite my having seen it some 15 or more times in the last 25 years paul lukas performance brings tears to my eyes and bette davis in one of her very few truly sympathetic roles is a delight the kids are as grandma says more like dressedup midgets than children but that only makes them more fun to watch and the mothers slow awakening to whats happening in the world and under her own roof is believable and startling if i had a dozen thumbs theyd all be up for this movie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stem_words(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "9mNGZS9e-mUK",
        "outputId": "2951ef5a-8927-4452-adb0-781b709efcb3"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'probabl my alltim favorit movi a stori of selfless sacrific and dedic to a nobl caus but it not preachi or bore it just never get old despit my have seen it some 15 or more time in the last 25 year paul luka perform bring tear to my eye and bett davi in one of her veri few truli sympathet role is a delight the kid are as grandma say more like dressedup midget than children but that onli make them more fun to watch and the mother slow awaken to what happen in the world and under her own roof is believ and startl if i had a dozen thumb theyd all be up for thi movi'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Lemmatizer**"
      ],
      "metadata": {
        "id": "2Norx1eu-46m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF6aoPNp_cIS",
        "outputId": "b2fd580b-3c65-4ecf-cffb-4b69a3c6f9d8"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "sentence = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\n",
        "punctuations=\"?:!.,;\"\n",
        "sentence_words = nltk.word_tokenize(sentence)\n",
        "sentence_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiLq3v_8-6zL",
        "outputId": "c6f41f8a-eee3-4444-f89b-12555e30dd8c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['He',\n",
              " 'was',\n",
              " 'running',\n",
              " 'and',\n",
              " 'eating',\n",
              " 'at',\n",
              " 'same',\n",
              " 'time',\n",
              " '.',\n",
              " 'He',\n",
              " 'has',\n",
              " 'bad',\n",
              " 'habit',\n",
              " 'of',\n",
              " 'swimming',\n",
              " 'after',\n",
              " 'playing',\n",
              " 'long',\n",
              " 'hours',\n",
              " 'in',\n",
              " 'the',\n",
              " 'Sun',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in sentence_words:\n",
        "    if word in punctuations:\n",
        "        sentence_words.remove(word)\n",
        "\n",
        "sentence_words\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wruzXyZM_N3F",
        "outputId": "88f32bde-2da5-468c-83a6-50a1683f5ade"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['He',\n",
              " 'was',\n",
              " 'running',\n",
              " 'and',\n",
              " 'eating',\n",
              " 'at',\n",
              " 'same',\n",
              " 'time',\n",
              " 'He',\n",
              " 'has',\n",
              " 'bad',\n",
              " 'habit',\n",
              " 'of',\n",
              " 'swimming',\n",
              " 'after',\n",
              " 'playing',\n",
              " 'long',\n",
              " 'hours',\n",
              " 'in',\n",
              " 'the',\n",
              " 'Sun']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
        "for word in sentence_words:\n",
        "    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word,pos='v')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laf3gBH6_XCi",
        "outputId": "19612972-761b-4186-dfec-0d13c1d80e68"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                Lemma               \n",
            "He                  He                  \n",
            "was                 be                  \n",
            "running             run                 \n",
            "and                 and                 \n",
            "eating              eat                 \n",
            "at                  at                  \n",
            "same                same                \n",
            "time                time                \n",
            "He                  He                  \n",
            "has                 have                \n",
            "bad                 bad                 \n",
            "habit               habit               \n",
            "of                  of                  \n",
            "swimming            swim                \n",
            "after               after               \n",
            "playing             play                \n",
            "long                long                \n",
            "hours               hours               \n",
            "in                  in                  \n",
            "the                 the                 \n",
            "Sun                 Sun                 \n"
          ]
        }
      ]
    }
  ]
}
